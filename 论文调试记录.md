# 1. Argoverse 数据集详解

 目录[数据集](https://curow.github.io/blog/argoverse/#数据集)[地图](https://curow.github.io/blog/argoverse/#地图)[Vector Map: Lane-Level Geometry](https://curow.github.io/blog/argoverse/#vector-map-lane-level-geometry)[Rasterized Map: Drivable Area](https://curow.github.io/blog/argoverse/#rasterized-map-drivable-area)[Rasterized Map: Ground Height](https://curow.github.io/blog/argoverse/#rasterized-map-ground-height)[竞赛](https://curow.github.io/blog/argoverse/#竞赛)[输入输出](https://curow.github.io/blog/argoverse/#输入输出)[评估指标](https://curow.github.io/blog/argoverse/#评估指标)[参考链接](https://curow.github.io/blog/argoverse/#参考链接)

Argoverse数据集介绍

## 数据集[Permalink](https://curow.github.io/blog/argoverse/#数据集)

Argoverse[1](https://curow.github.io/blog/argoverse/#fn:1)的数据集包括3D Tracing以及Motion Forecasting这两大类，我们关注的是Argoverse的Motion Forecasting这个数据集，包含了从超过1000个驾驶小时的数据中提取的327,790条有价值的场景，每个场景包含了自动驾驶车辆5秒钟的行驶轨迹，同时跟踪所有其他参与者（例如汽车，行人）。 并将它们分为208272个训练序列，40127个验证序列和79391个测试序列。

## 预测任务

https://eval.ai/web/challenges/challenge-page/454/overview

**Get started**

1. To get started, download Argoverse datasets and maps on our website: https://www.argoverse.org/.
2. Check out the Argoverse API and ask questions (if you have any) on GitHub: https://github.com/argoai/argoverse-api.
3. The baseline method on the leaderboard, similar to that described in our CVPR 2019 paper, is released at https://github.com/jagjeet-singh/argoverse-forecasting. We also provide the pre-computed features used in our paper [here](https://drive.google.com/open?id=1hHbpdlsgQL_XOxrUK0OuWGX0BxiGpxKY).





## Motion Forecasting

​		Argoverse Motion Forecasting是一个精选的集合，包含324,557个场景，每个场景5秒长，用于培训和验证。 每个场景包含以10hz采样的每个跟踪对象的2D鸟瞰图质心。  

​		为了创建这个集合，我们筛选了来自我们的自动驾驶测试车辆车队的1000多个小时的驾驶数据，以找到最具挑战性的部分——包括显示车辆在十字路口、车辆左转或右转以及车辆变换车道的部分。  

 是什么让这个数据集脱颖而出?
		这个数据集比目前可以从公开的自动驾驶数据集中挖掘出来的数据要大得多，我们的高清地图使预测物体的运动变得更容易。 收集，我们筛选了超过1000小时的自动驾驶测试车辆的驾驶数据，以找到最具挑战性的部分——包括显示车辆在十字路口、车辆左转或右转，以及车辆变换车道的部分。

## 画出带有地图的实际轨迹

```python
# In[]
# 总体修改

# set root_dir to the correct path to your dataset folder
root_dir = '/home/liqi/Argoverse/dataset/forecasting/train/data/'
afl = ArgoverseForecastingLoader(root_dir)
print('Total number of sequences:', len(afl))

seq_path = f"{root_dir}/119094.csv"

# 画出在高精度地图中agent的真实轨迹
viz_sequence(afl.get(seq_path).seq_df, show=True, smoothen=True)

agent_traj_viz = afl.get(seq_path).agent_traj
x = [traj[0] for traj in agent_traj_viz]
y = [traj[1] for traj in agent_traj_viz]
plt.plot(x, y, label="agent_traj")
plt.axis('square')
plt.axis('equal')
plt.show()

```



<img src="论文调试记录.assets/image-20211027171917622.png" alt="image-20211027171917622" style="zoom:67%;" />



- 红点是我们的agent
- 绿点为AV 自动驾驶车辆
- 淡蓝色为other

<img src="论文调试记录.assets/image-20211027171930634.png" alt="image-20211027171930634" style="zoom:67%;" />



### 根据前2s的轨迹生成候选轨迹

```python
# 加载高精度地图文件
avm = ArgoverseMap()
obs_len = 20

# 生成候选轨迹
agent_obs_traj = afl.get(seq_path).agent_traj[:obs_len]
candidate_centerlines = avm.get_candidate_centerlines_for_traj(
    agent_obs_traj, afl[index].city, viz=True)

```

<img src="论文调试记录.assets/image-20211027172023620.png" alt="image-20211027172023620" style="zoom:67%;" />

### 预测后3秒的轨迹

```python

# 最终预测出来的轨迹方向
agent_traj = afl.get(seq_path).agent_traj
lane_direction = avm.get_lane_direction(
    agent_traj[0], afl[index].city, visualize=True)
```

<img src="论文调试记录.assets/image-20211027172124839.png" alt="image-20211027172124839" style="zoom:67%;" />

## 画出任何index的候选轨迹中心线和理想轨迹

```PYTHON
# In[]
# 画出任意index的候选轨迹中心线和历史trajectory


def visualize_single_centerline(candidate_centerlines, xy, index):
    plt.figure(0, figsize=(8, 7))
    # for centerline_coords in candidate_centerlines:
    #     visualize_centerline(centerline_coords)
    visualize_centerline(candidate_centerlines[index])
    plt.plot(
        xy[:, 0],
        xy[:, 1],
        "-",
        color="#d33e4c",
        alpha=1,
        linewidth=1,
        zorder=15,
    )

    final_x = xy[-1, 0]
    final_y = xy[-1, 1]

    plt.plot(final_x, final_y, "o", color="#d33e4c",
             alpha=1, markersize=7, zorder=15)
    plt.xlabel("Map X")
    plt.ylabel("Map Y")
    plt.axis("on")
    plt.title("Number of candidates = {}".format(
        len(candidate_centerlines)))
    plt.show()


visualize_single_centerline(candidate_centerlines, agent_traj_viz, 0)
```

![image-20211101161002479](论文调试记录.assets/image-20211101161002479.png)

##  寻找最近的中心线

```PYTHON
def get_nearest_centerline(
        self, query_xy_city_coords: np.ndarray, city_name: str, visualize: bool = False
    ) -> Tuple[LaneSegment, float, np.ndarray]:

```

- 具有k近邻点的KD树（？？？）或对车道质心进行固定半径搜索是不可靠的，因为
  - (1) 整个地图的密度变化很大;
  - (2) 车道长度差别很大，这意味着质心并不代表附近的点。
  - 如果 MAX_LABEL_DIST_TO_LANE 没有找到车道，我们增加搜索半径。
- 正确的方法是比较**中心线**到**查询点x，y**的距离，例如Shapely的方法。
  - 我们**不是在所有点上循环**，而是预先比较每一个车道的Bounding Box。
- 我们使用closest_waypoint作为标准。
  - 使用最小的和到路点在许多情况下，不成比例的形状的车道段效果不太好。
  - 于是选择和最小为3-5的车道中心线最亲密的锚点。



## 计算最短距离车道中心距离

### 距离的绝对值index = 2 为例

![image-20211101214739463](论文调试记录.assets/image-20211101214739463.png)







### 轨迹偏差为绝对值



![image-20211101214754182](论文调试记录.assets/image-20211101214754182.png)

### 轨迹偏差具有符号 

- 使用函数get_nt_distance

- 可以获取某个点 法向量和切向量的距离
  - 法向量即为d
  - 切向量即为s

![image-20211105191116767](论文调试记录.assets/image-20211105191116767.png)

## 画Sl图

```PYTHON
# In[]
# 求取第index个数据包中  每个center轨迹中心 和 车辆轨迹 最近的距离 共50组

# 寻找中心线
lane_obj, confidence, dense_centerline = avm.get_nearest_centerline(
    agent_traj[0], city_name)
centerline = dense_centerline
# 使用ｇｅｔ_nt_distance可以得到切向和法向向量　
nt_distance = get_nt_distance(agent_traj, centerline)

# plt.figure(1)
# plt.plot(nt_distance[:, 0], color="#d33e4c",
#          alpha=1, markersize=7, zorder=15)
# plt.xlabel("Trajectory index")
# plt.ylabel("Closest Distance")
# plt.axis("on")
# plt.title("The distance between each quary point and the centerline")
# plt.show()

# 画出ＳＬ图
plt.figure(2)
plt.plot(nt_distance[:, 1], np.zeros(50), 'y')
plt.plot(nt_distance[:, 1], np.zeros(50)+1.5, 'b')
plt.plot(nt_distance[:, 1], np.zeros(50)-1.5, 'b')
plt.scatter(nt_distance[:, 1], nt_distance[:, 0], marker='o', color='k')
plt.axis([0, 40, -3, 3])
plt.xlabel("S")
plt.ylabel("D")
plt.axis("on")
plt.title("S-D")
# plt.show()

```



![image-20211105191040675](论文调试记录.assets/image-20211105191040675.png)



## Api函数解析

### get_nt_distance(agent_traj, centerline)

```python
# 使用ｇｅｔ_nt_distance可以得到切向和法向向量　
nt_distance = get_nt_distance(agent_traj, centerline)
```

- 获取每个index点的切向和法向的长度

### get_nearest_centerline

```python
lane_obj, confidence, dense_centerline = avm.get_nearest_centerline(agent_traj[0], city_name)
centerline = dense_centerline
```

- dense_centerline 为道路中心线
- confidence为在候选centerline中这条中心线的概率







# 2. 坐标转换问题

参考：https://blog.csdn.net/u013468614/article/details/108748016

https://zhuanlan.zhihu.com/p/304474902

- 百度planning：https://zhuanlan.zhihu.com/p/164635074

![image-20211101214739463](论文调试记录.assets/image-20211101214739463.png)

## python微元法计算函数曲线长度

参考：https://blog.csdn.net/ouening/article/details/82698830

- 通过微元法  可以求出centerline的每个index的长度
- 即在SL坐标系下的S
  - 弧长的定义：https://www.shuxuele.com/calculus/arc-length.html

```python
# 将xy—>SL坐标系

# 求第index的曲线弧长s
area_list = []
area_list = [np.sqrt((centerline[i][0]-centerline[i-1][0])
                     ** 2 + (centerline[i][1]-centerline[i-1][1])**2) for i in range(1, len(centerline))]
# area = sum(area_list)# 求和计算曲线在t:[0,2*pi]的长度
s_index = 1
s_area = []
s_area.append(0)
for i in range(1, len(centerline)):
    s_area.append(s_area[i-1] + area_list[i-1])
```





https://blog.csdn.net/yyd__/article/details/99679718



## 四元数和欧拉角的个人理解



欧垃角可以表示两个坐标之间的转换，但是存在一些弊端，比如万象锁，四元数也可以表述
问题分析：
比如，一个坐标系绕y轴旋转pi/2，那么我们就可以用欧拉角roll，pitch，yaw和四元数x，y，z，w进行表述，



```PYTHON
def yaw_to_quaternion3d(yaw: float) -> Tuple[float, float, float, float]:
    """
    Args:
    -   yaw: rotation about the z-axis, in radians
    Returns:
    -   qx,qy,qz,qw:    
    """
    qx, qy, qz, qw = Rotation.from_euler("z", yaw).as_quat()
    return qx, qy, qz, qw
```



# 3. 数据滤波

​		所有的特征都是通过**空间的导数**来估计的，因为数据集只提供了**车辆的位置和时间戳**。基于表 iv，当我们从原始数据中估计特征时，可能会突出显示大量的噪声，从而导致不切实际的测量，因此，我们应用了两个滤波器来降低噪声，

- 一个是扩展卡尔曼滤波器滤波器(ekf) ，另一个是 savitzkygolay 滤波器。 savitzkygolay 滤波器的降噪量比 ekf 大，虽然这种技术使用多项式插值来平滑数据
- 而 ekf 使用车辆运动的动态方程，使用方程式进行预测，并利用观测结果进行修正。

<img src="论文调试记录.assets/image-20211115100839043.png" alt="image-20211115100839043" style="zoom:50%;" />



## savgol 滤波器

/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/argoverse_template/util/savgol_filter.py

**- 什么是savgol_filter**

- Savitzky-Golay滤波器最初由Savitzky和Golay于1964年提出。广泛地运用于数据流平滑除噪，是一种在时域内基于局域多项式最小二乘法拟合的滤波方法。这种滤波器最大的特点在于在滤除噪声的同时可以确保信号的形状、宽度不变。
- 它对信号的操作是在时域内对window_length内的数据进行多项式拟合。而从频域上看，这种拟合实际就是通过了低频数据，而滤掉了高频数据。
- 这种滤波其实是一种移动窗口的加权平均算法，但是其**加权系数不是简单的常数窗口，而是通过在滑动窗口内对给定高阶多项式的最小二乘拟合得出**。

```python
	def _savgol_traj(self, traj:np.ndarray)->np.ndarray:
		'''
			applied a Savitzky-Golov filter to the trajectory
			 - path, velocity, acceleration and jerk

			- params:
				traj : nd.array : path [[x,y]] (m,2)
			- return:
				filtered : nd.array : [[x,y,v_x, v_y, a_x, a_y, j_x, j_y]]
		'''
		self.savgol.set_window_size(traj.shape[0]//2)

		return self.savgol.process(traj)
```







## EKF滤波

/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/argoverse_template/util/ekf_filter.py

```python
	def _ekf_traj(self, traj:np.ndarray)->np.ndarray:
		'''
			compute features using ekf 
			 - path, velocity, acceleration and jerk

			- params:
				traj : nd.array : path [[x,y]] (m,2)
			- return:
				filtered : nd.array : [[x,y,v_x, v_y, a_x, a_y, j_x, j_y]]
		'''

		return self.ekf.process(traj)
```





## EKF_savgol

- 先经过EKF 再 使用savgol

```python
	def _ekf_savgol_traj(self, traj:np.ndarray)->np.ndarray:
		'''
			applied a Savitzky-Golov filter to the trajectory after 
			compute features using ekf
			- path, velocity, acceleration and jerk

			- params:
				traj : nd.array : path [[x,y]] (m,2)
			- return:
				filtered : nd.array : [[x,y,v_x, v_y, a_x, a_y, j_x, j_y]]
		'''
		ekf_traj = self.ekf.process(traj)
		
		self.savgol.set_window_size(traj.shape[0]//2)
		
		return self.savgol.filter(ekf_traj)
```





## 画图对比

**/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/argoverse_template/argoverse_test.py**

### 箱型图

- raw  ekf  savgol  ekf-savgol 对比
- ekf savgol ekf-savgol 对比

<img src="硕士论文提纲V5.assets/image-20211118163352483.png" alt="image-20211118163352483" style="zoom: 80%;" /><img src="硕士论文提纲V5.assets/image-20211118201916837.png" alt="image-20211118201916837" style="zoom:80%;" />

#### 指标对比

- acc  jerk   path  velindex =10

<img src="论文调试记录.assets/image-20211118204548776.png" alt="image-20211118204548776" style="zoom:80%;" /><img src="论文调试记录.assets/image-20211118204626035.png" alt="image-20211118204626035" style="zoom:80%;" />

<img src="论文调试记录.assets/image-20211118204428693.png" alt="image-20211118204428693" style="zoom:80%;" /><img src="论文调试记录.assets/image-20211118204447126.png" alt="image-20211118204447126" style="zoom:80%;" />







# 4. 特征提取

**/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/argoverse_template/extract_sequences.py**

- 主要作用是提取经过 EKF SAVGOL等过滤后的轨迹
-  可以得到变量[[x,y,v_x, v_y, a_x, a_y, j_x, j_y]]
- 保存成为npy文件
- 使用并行处理 即batch >1时  会乱，因为并行处理不考虑顺序

```PYTHON 
python extract_sequences.py --data_dir ~/Argoverse/argoverse-code/TNT-Trajectory-Predition/dataset/raw_data/train --feature_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/extract_sequences/ --mode train --batch_size 1 --obs_len 5 --filter ekf
```

<img src="论文调试记录.assets/image-20211114170332795.png" alt="image-20211114170332795" style="zoom:80%;" />

**11/15**

- 采用前9734个数据进行处理

![image-20211115144927889](论文调试记录.assets/image-20211115144927889.png)

![image-20211115145037011](论文调试记录.assets/image-20211115145037011.png)

- sequence_train_trajectory_5s.npy
  - shape = (9734,50,3)
  - sequence_index ,  time_len,  feature_size
  - 9734个轨迹文件，50个0.1s， [time_stemps, x, y]
- sequence_train_trajectory_s5_ekf.npy
  - shape = (9734, 49, 8)
  - 9734个轨迹文件， 49个经过EKF滤波后的数据， [x, y, vx, vy, ax, ay, jx, jy]

## features

**/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/util/features.py**

### 平均速度Mean

- 平均速度

```python
def get_mean_velocity(self, traj:np.ndarray) -> float:
    '''
			compute velocity

			- params: 
				- traj : np.ndarray : [x,y, vx, vy, ax, ay, jx, jy]
		'''

    vel = np.sqrt(np.power(traj[:,2], 2) + np.power(traj[:,3],2))

    return vel.mean()
```



### 平均加/减速度Mean

- 平均加减速度

```python
def get_mean_acc_deac(self, traj:np.ndarray) -> Tuple:
    '''
		compute mean acceleration (+) and deaceleration (-)
		- params: 
		- traj : np.ndarray : [x,y, vx, vy, ax, ay, jx, jy]
	'''
    vel = np.sqrt(np.power(traj[:,2], 2) + np.power(traj[:,3],2))
    acc = np.sqrt(np.power(traj[:,4], 2) + np.power(traj[:,5],2))

    diff_vel = np.ediff1d(vel)

    acc_pos = acc[np.where(diff_vel >= 0)[0] + 1]
    acc_neg = acc[np.where(diff_vel < 0)[0] + 1]

    acc_pos_mean = acc_pos.mean() if acc_pos.shape[0]>0 else 0.0
    acc_neg_mean = acc_neg.mean() if acc_neg.shape[0]>0 else 0.0

    return acc_pos_mean, acc_neg_mean
```



### 纵向加加速度std

```python
def get_std_lat_jerk(self, traj:np.ndarray) -> float:
	'''
		compute standard deviation of the lateral jerk
		- params:
			- traj : np.ndarray : [x, y, vx, vy, ax, ay, jx, jy]
		- return
			- std_jy : float
	'''
    return traj[:, 7].std()
```



### 处理features

```PYTHON
def process(self, sequence: np.ndarray) -> np.ndarray:
'''
    return the computed features
    - params:
    	sequence: np.ndarray : [x,y,vx, vy, ax, ay, jx, jy] (m, 8)
    - return:
    	features: np.ndarray : [mean_v, mean_acc, mean_deac, std_jy]
'''
    mean_v = self.get_mean_velocity(traj=sequence)
    mean_acc, mean_deac = self.get_mean_acc_deac(traj=sequence)
    std_jy = self.get_std_lat_jerk(traj=sequence)

    return np.array([mean_v, mean_acc, mean_deac, std_jy])
```









## **计算features**

**/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/compute_features.py**

- 需要对轨迹的特征提取文件npy
- 保存为**features_train_5s_ekf.npy**

```python
python compute_features.py --data_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/extract_sequences/ --feature_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/extract_sequences/ --mode train --batch_size 1 --obs_len 5 --filter ekf
```

![image-20211114170103282](论文调试记录.assets/image-20211114170103282.png)

![image-20211115145211404](论文调试记录.assets/image-20211115145211404.png)









## 轨迹分析

**/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/analysis_sequences.py**

-  需要经过滤波后生成的npy文件 **sequences_train_filtered_5s_ekf.npy**
-  可以对滤波后提取的特征进行分析
   - 分析特征为 速度 vel
   - 加速度acc
   - 加加速度 jerk
- 生成文件为 **features_train_5s_ekf.npy**

```python
vel = np.sqrt(np.power(all_data[:,2], 2) + np.power(all_data[:,3],2))
acc = np.sqrt(np.power(all_data[:,4], 2) + np.power(all_data[:,5],2))
jerk = np.sqrt(np.power(all_data[:,6], 2) + np.power(all_data[:,7],2))
```

![image-20211114165958809](论文调试记录.assets/image-20211114165958809.png)

## 特征分析

**/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/analysis_features.py**

- 需要经过滤波和轨迹分析后生成的npy文件 **features_train_5s_ekf.npy**
- 

```python
python analysis_features.py --data_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/extract_sequences/ --mode train --obs_len 5 --filter ekf
```

![image-20211115145708088](论文调试记录.assets/image-20211115145708088.png)



# 5. 驾驶员风格分类

## Fuzzy-1 类系统

**~/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t1**

```PYTHON
python fuzzy_t1.py --data_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/extract_sequences/ --rules_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t1/rules --result_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t1/result --mode train --expert_mode single --obs_len 5
```



![image-20211114195242227](论文调试记录.assets/image-20211114195242227.png)

- 对驾驶风格的分类

![image-20211114195338016](论文调试记录.assets/image-20211114195338016.png)



### rules 隶属度函数



![image-20211115111215753](论文调试记录.assets/image-20211115111215753.png)

![image-20211115111231400](论文调试记录.assets/image-20211115111231400.png)

![image-20211115111239760](论文调试记录.assets/image-20211115111239760.png)

![image-20211115111249594](论文调试记录.assets/image-20211115111249594.png)

## Fuzzy-2 类系统

```python
python fuzzy_t2.py --data_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/features/extract_sequences/ --rules_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/rules --result_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/result --mode train --expert_mode single --obs_len 5
```



![image-20211114201748831](论文调试记录.assets/image-20211114201748831.png)



![image-20211114201835857](论文调试记录.assets/image-20211114201835857.png)

### rules 隶属度规则

<img src="论文调试记录.assets/image-20211115110810210.png" alt="image-20211115110810210" style="zoom: 67%;" />



![image-20211115110856480](论文调试记录.assets/image-20211115110856480.png)

![image-20211115110908488](论文调试记录.assets/image-20211115110908488.png)

![image-20211115110918573](论文调试记录.assets/image-20211115110918573.png)

![image-20211115110928449](论文调试记录.assets/image-20211115110928449.png)



















# 6. 结果分析

-  需要t2fis 系统处理后的结果
-  生成tesult json文件

```python
python analysis_results.py --data_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/result --result_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/analysis/result
```

![image-20211115110018390](论文调试记录.assets/image-20211115110018390.png)



## 驾驶员风格数据提取

**/home/liqi/Argoverse/argoverse-code/dataset_process/extract_driving_style.py**

-  筛选后的index文件保存 
  - **/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/result/sequence_style_index_1369.npy**
- 原始轨迹文件数据
  - **/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/result/sequence_style_data_1369.npy**
- ekf滤波后轨迹文件
  - **/home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/result/ekf_sequence_style_data_1369.npy**





## 画图分析

```python
python plot_clusters.py --data_file /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/fuzzy_t2/result/results_fuzzyT2_train_5s_ekf.csv --result_dir /home/liqi/Argoverse/argoverse-code/t2fis_driving_style/analysis/result --algorithm fls_t2
```

- 分析生成的csv文件
- 画图？？？？

![image-20211115110050360](论文调试记录.assets/image-20211115110050360.png)



<img src="论文调试记录.assets/image-20211115151905238.png" alt="image-20211115151905238" style="zoom:150%;" />





# 7. HighD 数据集

## 各data 和 文件作用

- **/home/liqi/python_code/MasterPaper_code/Dataset_process/highD/data**
  - 从highD数据集中筛选的 Truck 的换道轨迹文件
  - 每个单独csv保存









## 数据集介绍

​			通过计算应该是使用20ms 进行的记录 0.05s

​			德国亚琛工业大学汽车工程研究所新近发布的HighD数据集是德国高速公路的大型自然车辆轨迹数据集，数据搜集自德国科隆附近的六个不同地点， 位置因车道数量和速度限制而异，记录的数据中包括轿车和卡车。数据集包括来自六个地点的11.5小时测量值和110 000车辆，所测量的车辆总行驶里程为45 000 km，还包括了5600条完整的变道记录。通过使用最先进的计算机视觉算法，定位误差通常小于十厘米。适用于驾驶员模型参数化、自动驾驶、交通模式分析等任务。

![å¨è¿éæå¥å¾çæè¿°](论文调试记录 (1)_cloudback.assets/20200317151809952.png)

```python
tracks[current_track] = {TRACK_ID: np.int64(group_id),  # for compatibility, int would be more space efficient
                                 FRAME: rows[FRAME].values,
                                 BBOX: bounding_boxes,
                                 X_VELOCITY: rows[X_VELOCITY].values,
                                 Y_VELOCITY: rows[Y_VELOCITY].values,
                                 X_ACCELERATION: rows[X_ACCELERATION].values,
                                 Y_ACCELERATION: rows[Y_ACCELERATION].values,
                                 FRONT_SIGHT_DISTANCE: rows[FRONT_SIGHT_DISTANCE].values,
                                 BACK_SIGHT_DISTANCE: rows[BACK_SIGHT_DISTANCE].values,
                                 THW: rows[THW].values,
                                 TTC: rows[TTC].values,
                                 DHW: rows[DHW].values,
                                 PRECEDING_X_VELOCITY: rows[PRECEDING_X_VELOCITY].values,
                                 PRECEDING_ID: rows[PRECEDING_ID].values,
                                 FOLLOWING_ID: rows[FOLLOWING_ID].values,
                                 LEFT_FOLLOWING_ID: rows[LEFT_FOLLOWING_ID].values,
                                 LEFT_ALONGSIDE_ID: rows[LEFT_ALONGSIDE_ID].values,
                                 LEFT_PRECEDING_ID: rows[LEFT_PRECEDING_ID].values,
                                 RIGHT_FOLLOWING_ID: rows[RIGHT_FOLLOWING_ID].values,
                                 RIGHT_ALONGSIDE_ID: rows[RIGHT_ALONGSIDE_ID].values,
                                 RIGHT_PRECEDING_ID: rows[RIGHT_PRECEDING_ID].values,
                                 LANE_ID: rows[LANE_ID].values
                                 }
```



## 数据格式

> https://github.com/Haoran-SONG/PiP-Planning-informed-Prediction/blob/master/README.md
>
> https://hkustconnect-my.sharepoint.com/personal/hsongad_connect_ust_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fhsongad%5Fconnect%5Fust%5Fhk%2FDocuments%2FShared%2FPiP%5Fmaterials%2Fdatasets
>
> https://www.highd-dataset.com/format

![image-20220214225942189](论文调试记录.assets/image-20220214225942189.png)

![image-20220214225956116](论文调试记录.assets/image-20220214225956116.png)

![image-20220214230007634](论文调试记录.assets/image-20220214230007634.png)

![image-20220214230022034](论文调试记录.assets/image-20220214230022034.png)



**处理好的数据**

```python
%% Fields in the final result:
% traj  : (data number)*(13+grid_num)
%{
1: Dataset Id
2: Vehicle Id
(Column in tracks)
|3 : Frame Id
|4 : Local X
|5 : Local Y
|6 : Lane Id
|7*: Lateral maneuver
|8*: Longitudinal maneuver
|9 : Length
|10: Width
|11: Class label
|12: Velocity
|13: Accerlation
|14-end*: Neighbor Car Ids at grid location
%}

% tracks: includes {Dataset_Id*Vehicle_Id}, each cell with (11+grid)*totalFramNum
%{
|1 : Frame Id
|2 : Local X
|3 : Local Y
|4 : Lane Id
|5 : Lateral maneuver
|6 : Longitudinal maneuver
|7 : Length
|8 : Width
|9 : Class label
|10: Velocity
|11: Accerlation
|12-end*: Neighbor Car Ids at grid location
%}

## NGSIM / HighD datasets are publicly available datasets
## First using preprocess code to make them into mat file with the following format:

'''
% Data: #row = data number, #column = 138 (13+grid_num)
%{
0: Dataset Id
1: Vehicle Id
|2 : Frame Id
|3 : Local X
|4 : Local Y
|5 : Lane Id
|6 : Lateral maneuver
|7 : Longitudinal maneuver
|8 : Length
|9 : Width
|10: Class label
|11: Velocity
|12: Accerlation
|13-137: Neighbor Car Ids at grid location
%}
'''


'''
% Tracks: cells: {Dataset_Id * Vehicle_Id}, each cell: #row = 136 (11+grid_num), #column=totalFramNum
%{
|0 : Frame Id
|1 : Local X
|2 : Local Y
|3 : Lane Id
|4 : Lateral maneuver
|5 : Longitudinal maneuver
|6 : Length
|7 : Width
|8 : Class label
|9 : Velocity
|10: Accerlation
|11-135: Neighbor Car Ids at grid location
'''



```





| dhw  | The Distance Headway. This value is set to 0, if no preceding vehicle exists.和领航车的距离 | [m]  |
| ---- | ------------------------------------------------------------ | ---- |
| thw  | The Time Headway. This value is set to 0, if no preceding vehicle exists. 和领航车的时间 | [s]  |
| ttc  | The Time-to-Collision. This value is set to 0, if no preceding vehicle or valid TTC exists. 和领航车的碰撞时间 | [s]  |





## 换道数据

**/home/liqi/python_code/MasterPaper_code/Dataset_process/Lane-change-feature-extraction**

- **处理后的CSV的HEAD**

```python
# In[]
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt

#——————FEATURES——————————
#Basic information of dataset (global information)
DATASET="dataset"
SCENE="scene"
SCENE_AVERAGE_SPEED="scene_avg_speed"

#Local environment information of target (ego) vehicle
CURRENT_LANE_WIDTH="current_lane_width" #in Frenet Coordinate
TOTAL_NUM_LANE="total_num_lane"
ROAD_SPEED_LIMIT="road_speed_limit"
CURRENT_ROAD_CURVATURE="current_road_curvature"
TRAFFIC_LIGHT = "traffic_light"

# Driving maneuver classification
CURRENT_DRIVING_MANEUVER="current_maneuver" # 0:lane change 1:borrow lane       
LEFT_RIGHT_MANEUVER="left_right_maveuver"  # left:0  right:1
CURRENT_LANE_FEATURE_ID="current_feature_lane_id"   # 车辆跨过的车道ID
CURRENT_LANE_AVERAGE_SPEED="current_lane_average_speed"
CURRENT_LANE_SPEED_LIMIT="current_lane_speed_limit"
INTENTION_LANE="intention_lane" # 意图车道（准备换到哪一条道路的ID）

# Target vehicle information
DISTANCE_TO_LANE="Distance_to_lane" 
CLASS = "class"     # 车辆的分类 car = 0,truck = 1
VEHICLE_WIDTH = "vehicle_width"
VEHICLE_HEIGHT = "vehicle_height"
S_LOCATION = "s_Location"
D_LOCATION = "d_Location"
S_VELOCITY = "s_Velocity"
D_VELOCITY = "d_Velocity"
HEADING_ANGLE = "heading_angle"
S_ACCELERATION = "s_Acceleration"
D_ACCELERATION = "d_Acceleration"
YAW_RATE = "yaw_rate"
S_JERK = "s_jerk"
D_JERK = "d_jerk"
DHW = "dhw" # 
THW = "thw" #
TTC = "ttc" # 
LEFT_LANE_TYPE="left_lane_type"
RIGHT_LANE_TYPE="right_lane_type"
STEERING_RATE_ENTROPY="steering_rate_entropy" # 车辆转向的变化率

#Interactive information of surrounding vehicles
IS_PRECEDING_VEHICLE="is_preceding_vehicle" 
IS_FOLLOWING_VEHICLE="is_following_vehicle"
IS_LANE_TO_CHANGE_PRECEDING_VEHICLE="is_LTC_preceding_vehicle"
IS_LANE_TO_CHANGE_ALONGSIDE_VEHICLE="is_LTC_alongside_vehicle"
IS_LANE_TO_CHANGE_FOLLOWING_VEHICLE="is_LTC_following_vehicle"
PRECEDING_VEHICLE_FEATURE="preceding_vehicle_feature"
FOLLOWING_VEHICLE_FEATURE="following_vehicle_feature"
LANE_TO_CHANGE_PRECEDING_VEHICLE_FEATURE="LTC_preceding_vehicle_feature"
LANE_TO_CHANGE_FOLLOWING_VEHICLE_FEATURE="LTC_following_vehicle_feature"
LANE_TO_CHANGE_ALONGSIDE_VEHICLE_FEATURE="LTC_alongside_vehicle_feature"
GAP="gap"
FORWARD_LANE_TO_CHANGE_THW="forward_LTC_thw"
FORWARD_LANE_TO_CHANGE_DHW="forward_LTC_dhw"
FORWARD_LANE_TO_CHANGE_TTC="forward_LTC_ttc"
BACKWARD_LANE_TO_CHANGE_THW="backward_LTC_thw"
BACKWARD_LANE_TO_CHANGE_DHW="backward_LTC_dhw"
BACKWARD_LANE_TO_CHANGE_TTC="backward_LTC_ttc"


#——————————————————————
# TRACK FILE
BBOX = "bbox"
VEHICLE_ID = "vehicle_id"
FRAME = "frame"
LANE_ID = "laneId"
X_VELOCITY = "xVelocity"
Y_VELOCITY = "yVelocity"
X_ACCELERATION = "xAcceleration"
Y_ACCELERATION = "yAcceleration"
PRECEDING_ID = "precedingId"
FOLLOWING_ID = "followingId"
LEFT_PRECEDING_ID = "leftPrecedingId"
LEFT_ALONGSIDE_ID = "leftAlongsideId"
LEFT_FOLLOWING_ID = "leftFollowingId"
RIGHT_PRECEDING_ID = "rightPrecedingId"
RIGHT_ALONGSIDE_ID = "rightAlongsideId"
RIGHT_FOLLOWING_ID = "rightFollowingId"


LC_DATA_HEAD = [VEHICLE_ID,DATASET,SCENE,SCENE_AVERAGE_SPEED,CURRENT_LANE_WIDTH,
                    TOTAL_NUM_LANE,ROAD_SPEED_LIMIT,CURRENT_ROAD_CURVATURE,TRAFFIC_LIGHT,CURRENT_DRIVING_MANEUVER,
                    LEFT_RIGHT_MANEUVER,CURRENT_LANE_FEATURE_ID,CURRENT_LANE_AVERAGE_SPEED,CURRENT_LANE_SPEED_LIMIT,INTENTION_LANE,
                    DISTANCE_TO_LANE,CLASS,VEHICLE_WIDTH,VEHICLE_HEIGHT,S_LOCATION,
                    D_LOCATION,S_VELOCITY,D_VELOCITY,HEADING_ANGLE,S_ACCELERATION,
                    D_ACCELERATION,YAW_RATE,S_JERK,D_JERK,DHW,
                    THW,TTC,LEFT_LANE_TYPE,RIGHT_LANE_TYPE,STEERING_RATE_ENTROPY,
                    IS_PRECEDING_VEHICLE,"preceding_class","preceding_width","preceding_height","preceding_s_loc","preceding_d_loc","preceding_s_velo","preceding_d_velo","preceding_s_acc","preceding_d_acc",
                    IS_FOLLOWING_VEHICLE,"following_class","following_width","following_height","following_s_loc","following_d_loc","following_s_velo","following_d_velo","following_s_acc","following_d_acc",
                    IS_LANE_TO_CHANGE_PRECEDING_VEHICLE,"LTC_preceding_class","LTC_preceding_width","LTC_preceding_height","LTC_preceding_s_loc","LTC_preceding_d_loc","LTC_preceding_s_velo","LTC_preceding_d_velo","LTC_preceding_s_acc","LTC_preceding_d_acc",
                    IS_LANE_TO_CHANGE_ALONGSIDE_VEHICLE,"LTC_alongside_class","LTC_alongside_width","LTC_alongside_height","LTC_alongside_s_loc","LTC_alongside_d_loc","LTC_alongside_s_velo","LTC_alongside_d_velo","LTC_alongside_s_acc","LTC_alongside_d_acc",
                    IS_LANE_TO_CHANGE_FOLLOWING_VEHICLE,"LTC_following_class","LTC_following_width","LTC_following_height","LTC_following_s_loc","LTC_following_d_loc","LTC_following_s_velo","LTC_following_d_velo","LTC_following_s_acc","LTC_following_d_acc",
                    GAP,FORWARD_LANE_TO_CHANGE_THW,FORWARD_LANE_TO_CHANGE_DHW,FORWARD_LANE_TO_CHANGE_TTC,
                    BACKWARD_LANE_TO_CHANGE_THW,BACKWARD_LANE_TO_CHANGE_DHW,BACKWARD_LANE_TO_CHANGE_TTC]

LC_DATA_PATH = '/home/liqi/highD/highD_raw/highD-dataset-v1.0/save_file/LC_vehcile_features_06.csv'





```



```python
class LC_DATA:
    def __init__(self,LC_DATA_PATH) -> None:
        # 读取经过lc处理过后的文件
        self.data = pd.read_csv(LC_DATA_PATH,header = None)
        self.data.columns = LC_DATA_HEAD
        # 只保留trunk的数据
        self.truck_data = self.data.drop(self.data[self.data[CLASS]!=2.0].index)
        self.truck_data.reset_index(drop=True, inplace=True)
    def get_ego_data(self,ids):
        return self.truck_data[self.truck_data[VEHICLE_ID]== ids]
    
    def get_ego_sl_traj(self,ids):
        return np.transpose(np.asarray([self.get_ego_data(ids)[S_LOCATION],self.get_ego_data(ids)[D_LOCATION]]))
    
    def get_ego_heading_angle(self,ids):
        return np.transpose(np.array([self.get_ego_data(ids)[HEADING_ANGLE]]))
    
    def get_ego_velocity(self,ids):
        return np.transpose(np.array([np.hypot(self.get_ego_data(ids)[S_VELOCITY],self.get_ego_data(ids)[D_VELOCITY])]))
        
        

lc_set = LC_DATA(LC_DATA_PATH)

```



- 提取的具有代表性的 Truck 换道操作的ID

![image-20220105161301054](论文调试记录.assets/image-20220105161301054.png)

![image-20220105161310897](论文调试记录.assets/image-20220105161310897.png)

![image-20220105161423061](论文调试记录.assets/image-20220105161423061.png)

![image-20220105161325043](论文调试记录.assets/image-20220105161325043.png)

### 1. 提取车辆轨迹 

![image-20220105162118290](论文调试记录.assets/image-20220105162118290.png)

```python
#提取车辆轨迹
id = 1122.0
ego_traj = lc_set.get_ego_sl_traj(id)
plt.subplot()
plt.plot(ego_traj[:,0],ego_traj[:,1],label = f'id = {id}')
plt.legend(loc = 'best')
plt.grid()
plt.show()
print(id)
```



![image-20220105161911544](论文调试记录.assets/image-20220105161911544.png)

### 2. 提取车辆速度m/s

```python
# 车辆速度
ego_velocity = lc_set.get_ego_velocity(id)
plt.subplot()
plt.plot(ego_traj[:,0],ego_velocity[:,0],label = f'yaw_id = {id}')
plt.legend(loc = 'best')
plt.grid()
plt.show()
```



![image-20220105161949369](论文调试记录.assets/image-20220105161949369.png)

### 3. 变道方向

- left = 0
- right = 1

```python
# 第id个车辆的变道方向
lc_set.get_ego_data(id)[LEFT_RIGHT_MANEUVER]

# OUT
5169    0.0
5170    0.0
5171    0.0
5172    0.0
5173    0.0
       ... 
5427    0.0
5428    0.0
5429    0.0
5430    0.0
5431    0.0
Name: left_right_maveuver, Length: 263, dtype: float64
```





### 4. 变道车道跨越ID

```PYTHON
# 变道时的当前车道 和 目标车道
lc_set.get_ego_data(id)[CURRENT_LANE_FEATURE_ID]

# OUT
5169    1.0
5170    1.0
5171    1.0
5172    1.0
5173    1.0
       ... 
5427    2.0
5428    2.0
5429    2.0
5430    2.0
5431    2.0
Name: current_feature_lane_id, Length: 263, dtype: float64
```

- 在此程序中 将 道路ID数据顺序改变了一下

  - 变道时的当前车道 和 目标车道

    lc_set.get_ego_data(id)[CURRENT_LANE_FEATURE_ID]

  - 11111111 1 1 1 22222222
  - 实际是从 8888888 8 87 7 7 77 77 7 



![image-20220105154745761](论文调试记录.assets/image-20220105154745761.png)

![image-20220105163722743](论文调试记录.assets/image-20220105163722743.png)

### 5. Preceding ID 领航车辆ID

- 







## 数据可视化





![image-20220105160734955](论文调试记录.assets/image-20220105160734955.png)







## 左右换道提取



**/home/liqi/python_code/MasterPaper_code/Human_Style_Analyse/LC_traj_all.py**

左转换道

<img src="论文调试记录.assets/image-20220126214704646.png" alt="image-20220126214704646" style="zoom:50%;" />

<img src="论文调试记录.assets/image-20220126215245663.png" alt="image-20220126215245663" style="zoom:50%;" />

右转换道 

<img src="论文调试记录.assets/image-20220126215305871.png" alt="image-20220126215305871" style="zoom:50%;" />

<img src="论文调试记录.assets/image-20220126214724631.png" alt="image-20220126214724631" style="zoom:50%;" />





## 换道风格提取

**/home/liqi/python_code/MasterPaper_code/Driving_style/features/analyse_highD_features.py**

对文件/home/liqi/python_code/MasterPaper_code/Driving_style/features/features_data/LC_Driving_Style_features_0128.csv

进行特征分析

![image-20220128232915145](论文调试记录.assets/image-20220128232915145.png)

![image-20220128232617582](论文调试记录.assets/image-20220128232617582.png)

![image-20220128235558666](论文调试记录.assets/image-20220128235558666.png)

![image-20220129001120864](论文调试记录.assets/image-20220129001120864.png)

![image-20220129001220143](论文调试记录.assets/image-20220129001220143.png)

![image-20220129002524153](论文调试记录.assets/image-20220129002524153.png)

![image-20220129004041586](论文调试记录.assets/image-20220129004041586.png)

<img src="论文调试记录.assets/image-20220128232646255.png" alt="image-20220128232646255" style="zoom:67%;" />



<img src="论文调试记录.assets/image-20220128232703242.png" alt="image-20220128232703242" style="zoom:67%;" />

<img src="论文调试记录.assets/image-20220128232714716.png" alt="image-20220128232714716" style="zoom:67%;" />

## 驾驶员风格分类

- **/home/liqi/python_code/MasterPaper_code/Driving_style/fuzzy_t2_highD.py**
  - 使用四个features进行分类的结果vel acc deac jerk

![image-20220207202334602](论文调试记录.assets/image-20220207202334602.png)











# 8. 贝塞尔曲线的轨迹规划

详细介绍bezier曲线

https://pomax.github.io/bezierinfo/zh-CN/index.html

<img src="论文调试记录.assets/image-20211201151807321.png" alt="image-20211201151807321" style="zoom: 67%;" />



## 1. 路径规划下的贝塞尔曲线

/home/liqi/PythonCode/MasterPaper_code/bezier_plan_test.py

<img src="论文调试记录.assets/image-20211201170925065.png" alt="image-20211201170925065" style="zoom:67%;" />









## 2. 计算贝塞尔曲线的控制点

- 使用公式法计算
- 三阶贝塞尔曲线

<img src="论文调试记录.assets/image-20211208140934780.png" alt="image-20211208140934780" style="zoom:67%;" />

- 四阶贝塞尔曲线

<img src="论文调试记录.assets/image-20211208140823521.png" alt="image-20211208140823521" style="zoom:67%;" />













## 3. Dtw 时间动态调整算法 计算相似轨迹 筛选不同控制点最优拟合

### 定1号控制点E  遍历end_line

<img src="论文调试记录.assets/image-20211203133939283.png" alt="image-20211203133939283" style="zoom:67%;" />



### 定2号控制点F  遍历start_line

<img src="论文调试记录.assets/image-20211203133955957.png" alt="image-20211203133955957" style="zoom:67%;" />



### 遍历start_line 和 end_line  寻找最优控制点

<img src="论文调试记录.assets/image-20211130182011963.png" alt="image-20211130182011963" style="zoom:67%;" />



- 最好的控制点用黄色*表示

<img src="论文调试记录.assets/image-20211130182103998.png" alt="image-20211130182103998" style="zoom:80%;" />

### 使用公式法计算的控制点轨迹相似度



- 





## 4. 轨迹曲率计算









## 4. 计算 控制点特征向量 $e_1$ $e_2$

 

![image-20211207193502304](论文调试记录.assets/image-20211207193502304.png)



## 运动学约束

​		受车辆转向半径的约束，须保证拟合的曲线上任意点曲率不小于车辆当前速度下的最小转向半径，在Bézier曲线上的任意点须满足

$κ = \frac{1}{R_{min}} $



### 计算bezier曲线的曲率

参考https://pomax.github.io/bezierinfo/zh-CN/index.html

<img src="论文调试记录.assets/image-20211201151836048.png" alt="image-20211201151836048" style="zoom:50%;" />

### 计算bezier曲线的导数







## 动力学约束

车辆动力学约束为防止车辆在转向过程中发生侧滑或侧倾，提升避让路径的舒适性，须选择适当的参数对侧向加速度、横摆角速度和侧向急动度进行约束［20］。

$a(t) ≤a_{max}$

$ \dot{φ}(t) ≤ \dot{φ}_{max}$

$J(t) = a^{'}(t) ≤J_{max}$

其中，车辆侧向**加速度**和**横摆角速度**由车**辆动力学模型估算得到**，而**侧向急动度通过轨迹段上航迹点之间的侧向加速度变化率计算获得**。





# 9. NGSIN 数据集



上面这个就是东山再起的原回答，进去网址后下载这个就是csv文件。

上面这个就是东山再起的原回答，进去网址后下载这个就是csv文件。<img src="论文调试记录.assets/v2-5c2deeaacdb640c22f18208ff0a4ec0a_720w-16385343901112.jpg" data-caption="" data-size="normal" data-rawwidth="720" data-rawheight="677" data-default-watermark-src="https://pic3.zhimg.com/50/v2-4143c11e07abe7df8aa9f598c776fbe9_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="720" data-original="https://pic2.zhimg.com/v2-5c2deeaacdb640c22f18208ff0a4ec0a_r.jpg?source=1940ef5c"/>

作者：令狐小侠侠
链接：https://www.zhihu.com/question/274784022/answer/1080649429
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

- Vehicle_ID 车辆ID
- Frame_ID 帧数
- Total_Frames 总帧数
- Global_Time 世界时间，时间戳是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总秒数，python中datetime模块有将秒数时间转换为年月日时间的函数[1]，需要注意的是数据中有一部分是秒数，有一部分是毫秒数，使用的时候需要注意
- Local_X 车辆前部中心相对于当前车道最左侧的距离（前进方向，即参考坐标系原点位于当前车道起始线的最左侧，x轴方向向右，y轴方向向前）
- Local_Y 车辆的前部中心相对于当前车道起始线的距离
- Global_X 车辆在CA State Plane III in NAD83坐标系下的x坐标
- Global_Y 车辆在CA State Plane III in NAD83坐标系下的x坐标
- v_length 车辆长度
- v_Width 车辆宽度
- v_Class 车辆类型，1 - 摩托车, 2 - 汽车, 3 - 卡车
- v_Vel 车辆瞬时速度
- v_Acc 车辆瞬时加速度
- Lane_ID 车辆当前的车道位置，车道1是最左侧车道，车道5是最右侧车道，车道6是Ventura Boulevard大道入口匝道和Cahuenga Boulevard大道出口匝道间的辅助车道，车道7是Ventura Boulevard大道的入口匝道，车道8是
- Cahuenga Boulevard的出口匝道O_Zone 车辆进入数据采集系统之前所在的区域，在101到111之间，详见数据分析报告
- D_Zone 车辆离开数据采集系统所进入的区域，在201到211之间，详见数据分析报告
- Int_ID 车辆所在交叉路口的id，在1到4之间，交叉路口1是最南侧的，交叉路口4是最北侧的，0意味着车辆不在交叉路口同行而是行驶在Lankershim Blvd道的某一个区域
- Section_ID 车辆所行驶的区域id，Lankershim Blvd大道被分为五个部分，交叉路口1以南的部分、交叉路口1和2之间的部分、2和3之间的部分、3和4之间部分以及4以北的部分，0意味着车辆不在Lankershim Blvd大道的区域内而在交叉路口部分
- Direction 车辆行驶方向，1-向东，2-向北，3-向西，4-向南
- Movement 车辆驾驶行为，1-直行，2-左转，3-右转
- Preceding 当前车道内的前车，0代表无前车
- Following 当前车道内跟着主车的后车id，0代表无后车
- Space_Headway 前视距离，主车前部中心距离前车前部中心的距离
- Time_Headway 前视时间，主车行驶到前车位置所需要的时间
- Location 道路或者高速公路名字





# 10. 换道数据提取

![image-20211203205657717](论文调试记录.assets/image-20211203205657717.png)

![image-20211203205648981](论文调试记录.assets/image-20211203205648981.png)





![image-20211203205839168](论文调试记录.assets/image-20211203205839168.png)





![image-20211203205831656](论文调试记录.assets/image-20211203205831656.png)



![](论文调试记录.assets/image-20211203205922849.png)





![image-20211203205934705](论文调试记录.assets/image-20211203205934705.png)

## 换道轨迹曲率

- 原始换道轨迹曲率变化

![image-20211207193518332](论文调试记录.assets/image-20211207193518332.png)





# 11. ELM（极限学习机）

##  基于python的ELM（极限学习机）分类及回归实现（附带自己数据链接及推导）

ELM主程序来源：参考[@QuantumEntanglement](https://blog.csdn.net/QuantumEntanglement/article/details/93674942?utm_source=app)
经过了小小的修改，十分感谢该博主
自己理解推导过程：从最小二乘法到极限学习机
![最小二乘法解析](论文调试记录.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzYwMTcy,size_16,color_FFFFFF,t_70.jpeg)![从最小二乘法到ELM过程推导](论文调试记录.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzYwMTcy,size_16,color_FFFFFF,t_70-16399883913641.jpeg)

## 1.分类

**数据说明**
![数据说明](论文调试记录.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzYwMTcy,size_16,color_FFFFFF,t_70-16399883913652.png)
**程序**

```python
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 29 10:59:58 2020

@author: 小小飞在路上
"""
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split  #数据集的分割函数
from sklearn.preprocessing import StandardScaler      #数据预处理
from sklearn import metrics
import pandas as pd
from sklearn.utils import shuffle

class RELM_HiddenLayer:

    """
        正则化的极限学习机
        :param x: 初始化学习机时的训练集属性X
        :param num: 学习机隐层节点数
        :param C: 正则化系数的倒数
    """

    def __init__(self, x, num, C=10):
        row = x.shape[0]
        columns = x.shape[1]
        rnd = np.random.RandomState()
        # 权重w
        self.w = rnd.uniform(-1, 1, (columns, num))
        # 偏置b
        self.b = np.zeros([row, num], dtype=float)
        for i in range(num):
            rand_b = rnd.uniform(-0.4, 0.4)
            for j in range(row):
                self.b[j, i] = rand_b
        self.H0 = np.matrix(self.softplus(np.dot(x, self.w) + self.b))
        self.C = C
        self.P = (self.H0.H * self.H0 + len(x) / self.C).I 
        #.T:转置矩阵,.H:共轭转置,.I:逆矩阵

    @staticmethod
    def sigmoid(x):
        """
            激活函数sigmoid
            :param x: 训练集中的X
            :return: 激活值
        """
        return 1.0 / (1 + np.exp(-x))

    @staticmethod
    def softplus(x):
        """
            激活函数 softplus
            :param x: 训练集中的X
            :return: 激活值
        """
        return np.log(1 + np.exp(x))

    @staticmethod
    def tanh(x):
        """
            激活函数tanh
            :param x: 训练集中的X
            :return: 激活值
        """
        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))

    # 分类问题 训练
    def classifisor_train(self, T):
        """
            初始化了学习机后需要传入对应标签T
            :param T: 对应属性X的标签T
            :return: 隐层输出权值beta
        """
        if len(T.shape) > 1:
            pass
        else:
            self.en_one = OneHotEncoder()
            T = self.en_one.fit_transform(T.reshape(-1, 1)).toarray()
            pass
        all_m = np.dot(self.P, self.H0.H)
        self.beta = np.dot(all_m, T)
        return self.beta

    # 分类问题 测试
    def classifisor_test(self, test_x):
        """
            传入待预测的属性X并进行预测获得预测值
            :param test_x:被预测标签的属性X
            :return: 被预测标签的预测值T
        """
        b_row = test_x.shape[0]
        h = self.softplus(np.dot(test_x, self.w) + self.b[:b_row, :])
        result = np.dot(h, self.beta)
        result =np.argmax(result,axis=1)
        return result
    
# In[]
#数据读取及划分
url = 'C:/Users/weixifei/Desktop/TensorFlow程序/data1.csv'
data = pd. read_csv(url, sep=',',header=None)
data=np.array(data)
data=shuffle(data)
X_data=data[:,:23]
Y=data[:,23]
labels=np.asarray(pd.get_dummies(Y),dtype=np.int8)

num_train=0.3
X_train,X_,Y_train,Y_=train_test_split(X_data,labels,test_size=num_train,random_state=20)
X_test,X_vld,Y_test,Y_vld=train_test_split(X_,Y_,test_size=0.1,random_state=20)

# In[]
#数据标准化处理
stdsc = StandardScaler() 
X_train=stdsc.fit_transform(X_train)
X_test=stdsc.fit_transform(X_test)
X_vld=stdsc.fit_transform(X_vld)
Y_true=np.argmax(Y_test,axis=1)

# In[]
#不同隐藏层结果对比
result=[] 
for j in range(1,300,50):
    a = RELM_HiddenLayer(X_train,j)
    a.classifisor_train(Y_train)
    predict = a.classifisor_test(X_test)
    acc=metrics.precision_score(predict,Y_true, average='macro')
#    result.append(pre)
    print('hidden- %d,acc：%f'%(j,acc))

```





**结果**
![分类结果插入图片描述](论文调试记录.assets/2020042122354711.png)



## 2.回归

**程序**

```python
"""
Created on Tue Apr 21 22:37:14 2020

@author: 小小飞在路上
"""
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (8, 5)
 
class RELM_HiddenLayer:

    """
        正则化的极限学习机
        :param x: 初始化学习机时的训练集属性X
        :param num: 学习机隐层节点数
        :param C: 正则化系数的倒数
    """

    def __init__(self, x, num, C=10):
        row = x.shape[0]
        columns = x.shape[1]
        rnd = np.random.RandomState()
        # 权重w
        self.w = rnd.uniform(-1, 1, (columns, num))
        # 偏置b
        self.b = np.zeros([row, num], dtype=float)
        for i in range(num):
            rand_b = rnd.uniform(-0.4, 0.4)
            for j in range(row):
                self.b[j, i] = rand_b
        self.H0 = np.matrix(self.sigmoid(np.dot(x, self.w) + self.b))
        self.C = C
        self.P = (self.H0.H * self.H0 + len(x) / self.C).I

    @staticmethod
    def sigmoid(x):
        """
            激活函数sigmoid
            :param x: 训练集中的X
            :return: 激活值
        """
        return 1.0 / (1 + np.exp(-x))
  
    # 回归问题 训练
    def regressor_train(self, T):
        """
            初始化了学习机后需要传入对应标签T
            :param T: 对应属性X的标签T
            :return: 隐层输出权值beta
        """
        all_m = np.dot(self.P, self.H0.H)
        self.beta = np.dot(all_m, T)
        return self.beta

    # 回归问题 测试
    def regressor_test(self, test_x):
        """
            传入待预测的属性X并进行预测获得预测值
            :param test_x:特征
            :return: 预测值
        """
        b_row = test_x.shape[0]
        h = self.sigmoid(np.dot(test_x, self.w) + self.b[:b_row, :])
        result = np.dot(h, self.beta)
        return result

#产生数据集
x=np.linspace(0,20,200)
noise=np.random.normal(0,0.08,200)
y=np.sin(x)+np.cos(0.5*x)+noise
#转化成二维形式
x=np.array(x).reshape(-1,1)
y=np.array(y).reshape(-1,1)


j=0
#绘制原始散点图
plt.plot(x,y,'or')

#不同隐藏层线条设置不同的颜色
color=['g','b','y','c','m']

#比较不同隐藏层拟合效果
for i in range(5,30,5):
    my_EML = RELM_HiddenLayer(x,i)
    my_EML.regressor_train(y)
    x_test = np.linspace(0,20,200).reshape(-1,1)
    y_test = my_EML.regressor_test(x_test)
    plt.plot(x_test,y_test,color[j])
    plt.title('EML_regress')
    plt.xlabel('x')
    plt.ylabel('y')
    j+=1
#增加图例
plt.legend([['original'],['hidden_5'],['hidden_10'],['hidden_15'],['hidden_20'],['hidden_25']],loc='upper right')
plt.show()

```





**结果**
![回归效果对比图](论文调试记录.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzYwMTcy,size_16,color_FFFFFF,t_70-16399884533467.png)
分类数据同上一博文数据：[数据链接博文](https://blog.csdn.net/qq_40360172/article/details/105171148)
参考：[ELM程序参考来源](https://blog.csdn.net/QuantumEntanglement/article/details/93674942?utm_source=app)
再次感谢该博主！！！



## 极限学习机（ELM）回归问题实现（python）多输入多输出

https://blog.csdn.net/qq_41918369/article/details/108231263?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-14&spm=1001.2101.3001.4242.7



```python
# -*- coding: utf-8 -*-

import numpy as np

from sklearn.preprocessing import OneHotEncoder

from sklearn.model_selection import train_test_split  #数据集的分割函数

from sklearn.preprocessing import StandardScaler      #数据预处理

from sklearn import metrics

import pandas as pd

from sklearn.utils import shuffle

import matplotlib.pyplot as plt





class RELM_HiddenLayer:



    """

        正则化的极限学习机

        :param x: 初始化学习机时的训练集属性X

        :param num: 学习机隐层节点数

        :param C: 正则化系数的倒数

    """



    def __init__(self, x, num, C=10):

        row = x.shape[0]

        columns = x.shape[1]

        rnd = np.random.RandomState()

        # 权重w

        self.w = rnd.uniform(-1, 1, (columns, num))

        # 偏置b

        self.b = np.zeros([row, num], dtype=float)

        for i in range(num):

            rand_b = rnd.uniform(-0.4, 0.4)

            for j in range(row):

                self.b[j, i] = rand_b

        self.H0 = np.matrix(self.sigmoid(np.dot(x, self.w) + self.b))

        self.C = C

        self.P = (self.H0.H * self.H0 + len(x) / self.C).I 

        #.T:共轭矩阵,.H:共轭转置,.I:逆矩阵



    @staticmethod

    def sigmoid(x):

        """

            激活函数sigmoid

            :param x: 训练集中的X

            :return: 激活值

        """

        return 1.0 / (1 + np.exp(-x))



    @staticmethod

    def softplus(x):

        """

            激活函数 softplus

            :param x: 训练集中的X

            :return: 激活值

        """

        return np.log(1 + np.exp(x))



    @staticmethod

    def tanh(x):

        """

            激活函数tanh

            :param x: 训练集中的X

            :return: 激活值

        """

        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))



    # 回归问题 训练

    def regressor_train(self, T):

        """

            初始化了学习机后需要传入对应标签T

            :param T: 对应属性X的标签T

            :return: 隐层输出权值beta

        """

    

 #       all_m = np.dot(self.P, self.H0.H)

 #       self.beta = np.dot(all_m, T)

 #       return self.beta

        all_m = np.dot(self.P, self.H0.H)

        self.beta = np.dot(all_m, T)



        return self.beta



    # 回归问题 测试

    def regressor_test(self, test_x):

        """

            传入待预测的属性X并进行预测获得预测值

            :param test_x:被预测标签的属性X

            :return: 被预测标签的预测值T

        """

        b_row = test_x.shape[0]

        h = self.sigmoid(np.dot(test_x, self.w) + self.b[:b_row, :])

   #     h = self.sigmoid(np.dot(test_x, self.w) + self.b[:b_row, :])  

        result = np.dot(h, self.beta)

 #       result =np.argmax(result,axis=1)

        return result

    

# In[]

#数据读取及划分

url = './data1.csv'

data = pd. read_csv(url, sep=',',header=None)

data=np.array(data)

data=shuffle(data)

X_data=data[:,:23]

Y=data[:,23:26]



print(Y)



#Y=np.array(Y).reshape(-1, 1)

#print(Y)

#labels=np.asarray(pd.get_dummies(Y),dtype=np.int32)

#asarray是将输入数据（get_dummies）转换为矩阵形式

#what=pd.get_dummies(Y)   

#get_dummies是将数据分成类，然后每一个数据，对应分类结果上写1，其他都是0



#print(what)

#下面3行代码就是将数据集随即按照num_train分成训练集和测试集，数据量大，就分了两部分

num_train=0.1

X_train,X_,Y_train,Y_=train_test_split(X_data,Y,test_size=num_train,random_state=20)

X_test,X_vld,Y_test,Y_vld=train_test_split(X_,Y_,test_size=0.1,random_state=20)



# In[]

#数据标准化处理

stdsc = StandardScaler() 

X_train=stdsc.fit_transform(X_train)

X_test=stdsc.fit_transform(X_test)

X_vld=stdsc.fit_transform(X_vld)



Y_true=Y_test

#Y_true=np.argmax(Y_test,axis=1)



# In[]

#不同隐藏层结果对比

result=[] 



for j in range(1,30,5):

 

    a = RELM_HiddenLayer(X_train,j)

    a.regressor_train(Y_train)

    num_data = len(X_test)

   

    predict = a.regressor_test(X_test)

    print(predict)

#    acc=metrics.precision_score(predict,Y_true, average='macro')

#    plt.scatter(2,4,s=200)

    for i in range(1,num_data,1):

           print('hidden- %d,predict1：%f,predict2：%f,predict3：%f'%(j,predict[i,0],predict[i,1],predict[i,2]))

          # print(predict[i])

       #plt.scatter(i,predict[i].tolist())

   #    plt.plot(i, predict[i],linewidth=5)

    #plt.show()

    

#    result.append(pre)

    

#    print('hidden- %d,acc：%f'%(j,acc))

```

参考 https://blog.csdn.net/qq_40360172/article/details/105175946
原博主已经写了分类问题，同时对二维的回归问题做了较好的归纳，本文参考其回归代码，并做了一定的修改，解决了多输入多输出的回归问题。
数据只是对原博主分类问题的输出上做了部分改动。
数据链接
百度网盘：https://pan.baidu.com/s/1At8OXL_otKoon29YZTAo-g
提取码：rmcq

数据更新链接：
链接：https://pan.baidu.com/s/1UkmxIznZqXVphBPjbPKQgg
提取码：cypx

感谢博主！



# 12. 论文出图设置

https://zhuanlan.zhihu.com/p/448986597

## 单个较小的图片 3.5*2.5 inc 或者 3\*3

```python
plt.figure(num=None, figsize=(3.5, 2.5),dpi=300)
plt.rcParams.update({"font.size":8})
plt.rcParams['font.family'] = ['sans-serif']  
plt.rcParams['font.sans-serif'] = ['Simhei']  
plt.rcParams['axes.unicode_minus'] = False  

plt.plot(train_nll["Step"],train_nll["Value"], label = 'Best_path')
plt.plot(vali_nll["Step"],vali_nll["Value"], label = 'Best_path')

plt.xlabel("迭代次数")
plt.ylabel("NLL")
plt.xticks(fontproperties = 'Times New Roman', fontsize=8)
plt.yticks(fontproperties = 'Times New Roman', fontsize=8)
plt.legend(loc = 'best')

plt.grid(True)
plt.savefig(r'fig1.png',bbox_inches='tight',dpi=300)

```

<img src="论文调试记录.assets/fig1.png" alt="fig1" style="zoom:50%;" />



## 单个较大的图片 6*2 inc

```python
plt.figure(num=None, figsize=(6, 2),dpi=300)
plt.rcParams.update({"font.size":8})
plt.rcParams['xtick.direction'] = 'in'#将x周的刻度线方向设置向内
plt.rcParams['ytick.direction'] = 'in'#将y轴的刻度方向设置向内
plt.rcParams['font.family'] = ['sans-serif']  
plt.rcParams['font.sans-serif'] = ['Simhei']  
plt.rcParams['axes.unicode_minus'] = False  


plt.plot(train_nll["Step"],train_nll["Value"], label = 'Train', linewidth=2)
plt.plot(vali_nll["Step"],vali_nll["Value"],linestyle='-', label = 'Valid', linewidth=2)

plt.xlabel("迭代次数")
plt.ylabel("NLL")
plt.xticks(fontproperties = 'Times New Roman', fontsize=6)
plt.yticks(fontproperties = 'Times New Roman', fontsize=6)
plt.legend(loc = 'best')
plt.grid(True)
plt.savefig(r'fig1.png',bbox_inches='tight',dpi=300)
plt.show()
```



<img src="论文调试记录.assets/RMSE.png" alt="RMSE" style="zoom:50%;" />

